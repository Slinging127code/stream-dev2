阿里云FlinkDataHub,阿里云QuickBl,阿里云流计算(StreamCompute),Hologres
数据采集与接入:使用 FlinkDataHub：利用 DataHub 提供的多种 SDK、API 和 Flume、Logstash 等第三方插件，将 APP、WEB、IoT 和数据库等产生的异构数据实时接入到 DataHub
使用阿里云流计算（StreamCompute）:从 DataHub 订阅数据，然后使用 StreamCompute 进行实时数据处理。用户只需具备少量的 SQL 知识就能灵活地解决实时计算的复杂问题
使用 Flink：如果使用 Flink，同样可以从 DataHub 读取数据，利用 Flink 强大的流批一体处理能力进行复杂的实时计算任务
使用 Hologres：Hologres 作为一站式实时数仓引擎，支持海量数据实时写入、更新、加工和分析。可以将经过流计算或 Flink 处理后的数据实时写入 Hologres 进行存储和管理
Flink面试题:
Flink对于迟到数据是怎么处理的
Flink中 WaterMark 和 Window 机制解决了流式数据的乱序问题，对于因为延迟而顺序有误的数据，可以根据eventTime进行业务处理，对于延迟的数据Flink也有自己的解决办法，主要的办法是给定一个允许延迟的时间，在该时间范围内仍可以接受处理延迟数据

设置允许延迟的时间是通过allowedLateness(lateness: Time)设置

保存延迟数据则是通过sideOutputLateData(outputTag: OutputTag[T])保存

获取延迟数据是通过DataStream.getSideOutput(tag: OutputTag[X])获取

Flink CEP编程中当状态没有到达的时候会将数据保存在哪里
在流式处理中，CEP 当然是要支持 EventTime 的，那么相对应的也要支持数据的迟到现象，也就是watermark的处理逻辑
CEP对未匹配成功的事件序列的处理，和迟到数据是类似的。在 Flink CEP的处理逻辑中，状态没有满足的和迟到的数据
都会存储在一个Map数据结构中，也就是说，如果我们限定判断事件序列的时长为5分钟，那么内存中就会存储5分钟的数据
这在我看来，也是对内存的极大损伤之一

Flink海量数据高效去重
基于状态后端。
基于HyperLogLog：不是精准的去重。
基于布隆过滤器（BloomFilter）；快速判断一个key是否存在于某容器，不存在就直接返回。
基于BitMap；用一个bit位来标记某个元素对应的Value，而Key即是该元素。由于采用了Bit为单位来存储数据，因此可以大大节省存储空间。
基于外部数据库；选择使用Redis或者HBase存储数据，我们只需要设计好存储的Key即可，不需要关心Flink任务重启造成的状态丢失问题。
讲述一下Flink中的窗口及应用?
滚动窗口
滚动窗口下窗口之间之间不重叠，且窗口长度是固定的。我们可以用TumblingEventTimeWindows和TumblingProcessingTimeWindows创建一个基于Event Time或Processing Time的滚动时间窗口。窗口的长度可以用org.apache.flink.streaming.api.windowing.time.Time中的seconds、minutes、hours和days来设置。

滑动窗口
滑动窗口以一个步长（Slide）不断向前滑动，窗口的长度固定。使用时，我们要设置Slide和Size。Slide的大小决定了Flink以多大的频率来创建新的窗口，Slide较小，窗口的个数会很多。Slide小于窗口的Size时，相邻窗口会重叠，一个事件会被分配到多个窗口；Slide大于Size，有些事件可能被丢掉。

会话窗口
会话窗口根据Session gap切分不同的窗口，当一个窗口在大于Session gap的时间内没有接收到新数据时，窗口将关闭。在这种模式下，窗口的长度是可变的，每个窗口的开始和结束时间并不是确定的。我们可以设置定长的Session gap，也可以使用SessionWindowTimeGapExtractor动态地确定Session gap的长度。

Global window
将所有相同keyed的元素分配到一个窗口里。

窗口函数
窗口函数就是这四个：ReduceFunction，AggregateFunction，FoldFunction，ProcessWindowFunction。前两个执行得更有效，因为Flink可以增量地聚合每个到达窗口的元素。